<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Gorav Jindal | Publications</title>
  <meta name="description" content="Gorav Jindal's personal and academic webpage.
">

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Gorav</strong> Jindal
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">About</a>

        <!-- Blog -->
        <a class="page-link" href="/blog/">Blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="/publications/">Publications</a>
          
        
          
            <a class="page-link" href="/teaching/">Teaching</a>
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <h5 class="post-description">Publications  in reversed chronological order</h5>
  </header>

  <article class="post-content Publications clearfix">
    
<h3 class="year">2019</h3>
<ol class="bibliography"><li>

<div id="bbjpsoda19">
  
    <span class="title">A Deterministic PTAS for the Algebraic Rank of Bounded Degree Polynomials</span>
    <span class="author">
      
        
          
            
              
                <a href="https://sites.google.com/view/vishwas" target="_blank">Bhargava, Vishwas</a>, 
              
            
          
        
      
        
          
            
              
                <a href="https://www-cc.cs.uni-saarland.de/mblaeser/" target="_blank">Bläser, Markus</a>, 
              
            
          
        
      
        
          
            
              <em>Jindal, Gorav</em>,
            
          
        
      
        
          
            
              
                and <a href="http://people.mpi-inf.mpg.de/~apandey/" target="_blank">Pandey, Anurag</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/bbjpsoda19/paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i>PDF</a>]
  
  
  
  
  
  
    [<a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611975482.41" target="_blank">URL</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>
          We present a deterministic polynomial time approximation scheme (PTAS) for computing the algebraic rank of a set of bounded degree polynomials. The notion of algebraic rank naturally generalizes the notion of rank in linear algebra, i.e., instead of considering only the linear dependencies, we also consider higher degree algebraic dependencies among the input polynomials.

More specifically, we give an algorithm that takes as input a set of polynomials with degrees bounded by d, and a rational number ∊ &gt; 0 and runs in time , where M(n) is the time required to compute the rank of an n × n matrix (with field entries), and finally outputs a number r, such that r is at least (1 – ∊) times the algebraic rank of f.

Our key contribution is a new technique which allows us to achieve the higher degree generalization of the results by Bläser, Jindal, Pandey (CCC’17) who gave a deterministic PTAS for computing the rank of a matrix with homogeneous linear entries. It is known that a deterministic algorithm for exactly computing the rank in the linear case is already equivalent to the celebrated Polynomial Identity Testing (PIT) problem which itself would imply circuit complexity lower bounds (Kabanets, Impagliazzo, STOC’03).

Such a higher degree generalization is already known to a much stronger extent in the non-commutative world, where the more general case in which the entries of the matrix are given by polysized formulas reduces to the case where the entries are given by linear polynomials using Higman’s trick, and in the latter case, one can also compute the exact rank in polynomial time (Garg, Gurvits, Oliviera, Wigderson, FOCS’16, Ivanyos, Qiao, Subrahmanyam, ITCS’17). Higman’s trick only preserves the co-rank, hence it cannot be used to reduce the problem of rank approximation to the case when the matrix entries are linear polynomials. Thus our work can also be seen as a step towards bridging the knowledge gap between the non-commutative world and the commutative world.
          </p>
  </span>
  
</div>
</li>
<li>

<div id="bjitcs19">
  
    <span class="title">On the Complexity of Symmetric Polynomials</span>
    <span class="author">
      
        
          
            
              
                <a href="https://www-cc.cs.uni-saarland.de/mblaeser/" target="_blank">Bläser, Markus</a>, 
              
            
          
        
      
        
          
            
              and <em>Jindal, Gorav</em>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 10th Innovations in Theoretical Computer Science  Conference (ITCS 2019)</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/bjitcs19/paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i>PDF</a>]
  
  
  
  
  
  
    [<a href="http://drops.dagstuhl.de/opus/volltexte/2018/10140" target="_blank">URL</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The fundamental theorem of symmetric polynomials states that for a symmetric polynomial f_Sym in C[x_1,x_2,...,x_n], there exists a unique "witness" f in C[y_1,y_2,...,y_n] such that f_Sym=f(e_1,e_2,...,e_n), where the e_i’s are the elementary symmetric polynomials. In this paper, we study the arithmetic complexity L(f) of the witness f as a function of the arithmetic complexity L(f_Sym) of f_Sym. We show that the arithmetic complexity L(f) of f is bounded by poly(L(f_Sym),deg(f),n). To the best of our knowledge, prior to this work only exponential upper bounds were known for L(f). The main ingredient in our result is an algebraic analogue of Newton’s iteration on power series. As a corollary of this result, we show that if VP != VNP then there exist symmetric polynomial families which have super-polynomial arithmetic complexity. Furthermore, we study the complexity of testing whether a function is symmetric. For polynomials, this question is equivalent to arithmetic circuit identity testing. In contrast to this, we show that it is hard for Boolean functions.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2018</h3>
<ol class="bibliography"><li>

<div id="bjptoc2018">
  
    <span class="title">A Deterministic PTAS for the Commutative Rank of Matrix Spaces</span>
    <span class="author">
      
        
          
            
              
                <a href="https://www-cc.cs.uni-saarland.de/mblaeser/" target="_blank">Bläser, Markus</a>, 
              
            
          
        
      
        
          
            
              <em>Jindal, Gorav</em>,
            
          
        
      
        
          
            
              
                and <a href="http://people.mpi-inf.mpg.de/~apandey/" target="_blank">Pandey, Anurag</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Theory of Computing</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/bjptoc2018/paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i>PDF</a>]
  
  
  
  
  
  
    [<a href="http://www.theoryofcomputing.org/articles/v014a003" target="_blank">URL</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>
           We consider the problem of computing the commutative rank of a given matrix space B⊆Fn×n, that is, given a basis of B, find a matrix of maximum rank in B. This problem is fundamental, as it generalizes several computational problems from algebra and combinatorics. For instance, checking if the commutative rank of the space is n, subsumes problems such as testing perfect matching in graphs and identity testing of algebraic branching programs. Finding an efficient deterministic algorithm for the commutative rank is a major open problem, although there is a simple and efficient randomized algorithm for it. Recently, there has been a series of results on computing the non-commutative rank of matrix spaces in deterministic polynomial time. Since the non-commutative rank of any matrix space is at most twice the commutative rank, one immediately gets a deterministic 1/2

-approximation algorithm for the commutative rank. It is a natural question whether this approximation ratio can be improved. In this paper, we answer this question affirmatively.

We present a deterministic polynomial-time approximation scheme (PTAS) for computing the commutative rank of a given matrix space. More specifically, given a matrix space B⊆Fn×n
and a rational number ϵ&gt;0, we give an algorithm that runs in time O(n4+3/ϵ) and computes a matrix A∈B such that the rank of A is at least (1−ϵ) times the commutative rank of B. The algorithm is the natural greedy algorithm. It always takes the first set of k matrices that will increase the rank of the matrix constructed so far until it does not find any improvement, where the size k of the set depends on ϵ. </p>
  </span>
  
</div>
</li>
<li>

<div id="bijvstoc18">
  
    <span class="title">Generalized Matrix Completion and Algebraic Natural Proofs</span>
    <span class="author">
      
        
          
            
              
                <a href="https://www-cc.cs.uni-saarland.de/mblaeser/" target="_blank">Bläser, Markus</a>, 
              
            
          
        
      
        
          
            
              
                <a href="http://pcwww.liv.ac.uk/~iken/" target="_blank">Ikenmeyer, Christian</a>, 
              
            
          
        
      
        
          
            
              <em>Jindal, Gorav</em>,
            
          
        
      
        
          
            
              
                and <a href="https://www.math.ku.dk/english/about/news/new-names/vladimir-lysikov-postdoc/" target="_blank">Lysikov, Vladimir</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 50th Annual ACM SIGACT Symposium on Theory of Computing</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/bijvstoc18/paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i>PDF</a>]
  
  
  
  
  
  
    [<a href="http://doi.acm.org/10.1145/3188745.3188832" target="_blank">URL</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Algebraic natural proofs were recently introduced by Forbes, Shpilka and Volk (Proc. of the 49th Annual ACM SIGACT Symposium on Theory of Computing (STOC), pages 653–664, 2017) and independently by Grochow, Kumar, Saks and Saraf (CoRR, abs/1701.01717, 2017) as an attempt to transfer Razborov and Rudich’s famous barrier result (J. Comput. Syst. Sci., 55(1): 24–35, 1997) for Boolean circuit complexity to algebraic complexity theory. Razborov and Rudich’s barrier result relies on a widely believed assumption, namely, the existence of pseudo-random generators. Unfortunately, there is no known analogous theory of pseudo-randomness in the algebraic setting. Therefore, Forbes et al. use a concept called succinct hitting sets instead. This assumption is related to polynomial identity testing, but it is currently not clear how plausible this assumption is. Forbes et al. are only able to construct succinct hitting sets against rather weak models of arithmetic circuits.

Generalized matrix completion is the following problem: Given a matrix with affine linear forms as entries, find an assignment to the variables in the linear forms such that the rank of the resulting matrix is minimal. We call this rank the completion rank. Computing the completion rank is an NP-hard problem. As our first main result, we prove that it is also NP-hard to determine whether a given matrix can be approximated by matrices of completion rank ≤ b. The minimum quantity b for which this is possible is called border completion rank (similar to the border rank of tensors). Naturally, algebraic natural proofs can only prove lower bounds for such border complexity measures. Furthermore, these border complexity measures play an important role in the geometric complexity program.

Using our hardness result above, we can prove the following barrier: We construct a small family of matrices with affine linear forms as entries and a bound b, such that at least one of these matrices does not have an algebraic natural proof of polynomial size against all matrices of border completion rank b, unless coNP ⊆ ∃ BPP. This is an algebraic barrier result that is based on a well-established and widely believed conjecture. The complexity class ∃ BPP is known to be a subset of the more well known complexity class in the literature. Thus ∃ BPP can be replaced by MA in the statements of all our results. With similar techniques, we can also prove that tensor rank is hard to approximate.

Furthermore, we prove a similar result for the variety of matrices with permanent zero. There are no algebraic polynomial size natural proofs for the variety of matrices with permanent zero, unless P#P ⊆ ∃ BPP. On the other hand, we are able to prove that the geometric complexity theory approach initiated by Mulmuley and Sohoni (SIAM J. Comput. 31(2): 496–526, 2001) yields proofs of polynomial size for this variety, therefore overcoming the natural proofs barrier in this case.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2017</h3>
<ol class="bibliography"><li>

<div id="bjpccc2017">
  
    <span class="title">Greedy Strikes Again: A Deterministic PTAS for Commutative Rank of Matrix Spaces</span>
    <span class="author">
      
        
          
            
              
                <a href="https://www-cc.cs.uni-saarland.de/mblaeser/" target="_blank">Bläser, Markus</a>, 
              
            
          
        
      
        
          
            
              <em>Jindal, Gorav</em>,
            
          
        
      
        
          
            
              
                and <a href="http://people.mpi-inf.mpg.de/~apandey/" target="_blank">Pandey, Anurag</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 32nd Computational Complexity Conference (CCC 2017)</em>
    
    
      2017
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/bjpccc2017/paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i>PDF</a>]
  
  
  
  
  
  
    [<a href="http://drops.dagstuhl.de/opus/volltexte/2017/7519" target="_blank">URL</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>
            We consider the problem of commutative rank computation of a given matrix space. A matrix space is a (linear) subspace of the (linear) space of n x n matrices over a given field. The problem is fundamental, as it generalizes several computational problems from algebra and combinatorics. For instance, checking if the commutative rank of the space is n, subsumes problems such as testing perfect matching in graphs and identity testing of algebraic branching programs. An efficient deterministic computation of the commutative rank is a major open problem, although there is a simple and efficient randomized algorithm for it. Recently, there has been a series of results on computing the non-commutative rank of matrix spaces in deterministic polynomial time. Since the non-commutative rank of any matrix space is at most twice the commutative rank, one immediately gets a deterministic 1/2-approximation algorithm for the computation of the commutative rank. This leads to a natural question of whether this approximation ratio can be improved. In this paper, we answer this question affirmatively. We present a deterministic Polynomial-time approximation scheme (PTAS) for computing the commutative rank of a given matrix space B. More specifically, given a matrix space and a rational number e &gt; 0, we give an algorithm, that runs in time O(n^(4 + 3/e)) and computes a matrix A in the given matrix space B such that the rank of A is at least (1-e) times the commutative rank of B. The algorithm is the natural greedy algorithm. It always takes the first set of k matrices that will increase the rank of the matrix constructed so far until it does not find any improvement, where the size of the set k depends on e.
            </p>
  </span>
  
</div>
</li>
<li>

<div id="jkpsapprox17">
  
    <span class="title">Density Independent Algorithms for Sparsifying k-Step Random Walks</span>
    <span class="author">
      
        
          
            
              <em>Jindal, Gorav</em>,
            
          
        
      
        
          
            
              
                <a href="http://people.mpi-inf.mpg.de/~pkolev/" target="_blank">Kolev, Pavel</a>, 
              
            
          
        
      
        
          
            
              
                <a href="https://www.cc.gatech.edu/~rpeng/" target="_blank">Peng, Richard</a>, 
              
            
          
        
      
        
          
            
              
                and <a href="https://www.cc.gatech.edu/~ssawlani3/" target="_blank">Sawlani, Saurabh</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques (APPROX/RANDOM 2017)</em>
    
    
      2017
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/jkpsapprox17/paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i>PDF</a>]
  
  
  
  
  
  
    [<a href="http://drops.dagstuhl.de/opus/volltexte/2017/7563" target="_blank">URL</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We give faster algorithms for producing sparse approximations of the transition matrices of k-step random walks on undirected and weighted graphs. These transition matrices also form graphs, and arise as intermediate objects in a variety of graph algorithms. Our improvements are based on a better understanding of processes that sample such walks, as well as tighter bounds on key weights underlying these sampling processes. On a graph with n vertices and m edges, our algorithm produces a graph with about nlog(n) edges that approximates the k-step random walk graph in about m + k^2 nlog^4(n) time. In order to obtain this runtime bound, we also revisit "density independent" algorithms for sparsifying graphs whose runtime overhead is expressed only in terms of the number of vertices.</p>
  </span>
  
</div>
</li>
<li>

<div id="jsissac17">
  
    <span class="title">Efficiently Computing Real Roots of Sparse Polynomials</span>
    <span class="author">
      
        
          
            
              <em>Jindal, Gorav</em>,
            
          
        
      
        
          
            
              
                and <a href="http://people.mpi-inf.mpg.de/~msagralo/" target="_blank">Sagraloff, Michael</a> 
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 2017 ACM on International Symposium on Symbolic and Algebraic Computation</em>
    
    
      2017
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/jsissac17/paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i>PDF</a>]
  
  
  
  
  
  
    [<a href="http://doi.acm.org/10.1145/3087604.3087652" target="_blank">URL</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We propose an efficient algorithm to compute the real roots of a sparse polynomial f∈R[x] having k non-zero real-valued coefficients. It is assumed that arbitrarily good approximations of the non-zero coefficients are given by means of a coefficient oracle. For a given positive integer L, our algorithm returns disjoint disks Δ1,...,Δs⊂C, with s&lt;2k, centered at the real axis and of radius less than 2-L together with positive integers μ1,...,μs such that each disk Δi contains exactly μi roots of f counted with multiplicity. In addition, it is ensured that each real root of f is contained in one of the disks. If f has only simple real roots, our algorithm can also be used to isolate all real roots. The bit complexity of our algorithm is polynomial in k and log n, and near-linear in L and τ, where 2-τ and 2τ constitute lower and upper bounds on the absolute values of the non-zero coefficients of f, and n is the degree of f. For root isolation, the bit complexity is polynomial in k and log n, and near-linear in τ and logσ-1, where σ denotes the separation of the real roots.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2014</h3>
<ol class="bibliography"><li>

<div id="bjissac14">
  
    <span class="title">A New Deterministic Algorithm for Sparse Multivariate Polynomial Interpolation</span>
    <span class="author">
      
        
          
            
              
                <a href="https://www-cc.cs.uni-saarland.de/mblaeser/" target="_blank">Bläser, Markus</a>, 
              
            
          
        
      
        
          
            
              and <em>Jindal, Gorav</em>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 39th International Symposium on Symbolic and Algebraic Computation</em>
    
    
      2014
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/bjissac14/paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i>PDF</a>]
  
  
  
  
  
  
    [<a href="http://doi.acm.org/10.1145/2608628.2608648" target="_blank">URL</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>We present a deterministic algorithm to interpolate an m-sparse n-variate polynomial which uses poly(n, m, log(H), log(d)) bit operations. Our algorithm works over the integers. Here H is a bound on the magnitude of the coefficient values of the given polynomial. The degree of given polynomial is bounded by d and m is upper bound on number of monomials. This running time is polynomial in the output size. Our algorithm only requires modular black box access to the given polynomial, as introduced in [12]. As an easy consequence, we obtain an algorithm to interpolate polynomials represented by arithmetic circuits.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2012</h3>
<ol class="bibliography"><li>

<div id="jsarxiv12">
  
    <span class="title">Subtraction makes computing integers faster</span>
    <span class="author">
      
        
          
            
              
                <a href="https://sites.google.com/site/thsaranurak/" target="_blank">Saranurak, Thatchaphol</a>, 
              
            
          
        
      
        
          
            
              and <em>Jindal, Gorav</em>
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>arXiv preprint arXiv:1212.2549</em>
    
    
      2012
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abstract</a>]
  
  
  
  
    [<a href="/assets/pdf/jsarxiv12/paper.pdf" target="_blank"><i class="fas fa-file-pdf"></i>PDF</a>]
  
  
  
  
  
  
    [<a href="https://arxiv.org/abs/1212.2549" target="_blank">URL</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>
    We show some facts regarding the question whether, for any number n, the length of the shortest Addition Multiplications Chain (AMC) computing n is polynomial in the length of the shortest division-free Straight Line Program (SLP) that computes n.
    If the answer to this question is "yes", then we can show a stronger upper bound for PosSLP, the important problem which essentially captures the notion of efficient computation over the reals. If the answer is "no", then this would demonstrate how subtraction helps generating integers super-polynomially faster, given that addition and multiplication can be done in unit time.
    In this paper, we show that, for almost all numbers, AMCs and SLPs need same asymptotic length for computation. However, for one specific form of numbers, SLPs are strictly more powerful than AMCs by at least one step of computation.</p>
  </span>
  
</div>
</li></ol>


  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2019 Gorav Jindal.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://www.netlify.com/" target="_blank">Netlify</a>.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-116117814-1', 'auto');
ga('send', 'pageview');
</script>


<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">

MathJax.Hub.Config({
	jax: ["input/TeX","output/HTML-CSS"],
  extensions: ["tex2jax.js","MathMenu.js","MathZoom.js"],
  tex2jax: 
		{
			inlineMath: [ ['$','$'], ['\\(','\\)'] ],
			displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
    processEnvironments: true,
			    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			processEscapes: true
		},
	TeX:
		{ 
			equationNumbers: { autoNumber: "AMS" },
			extensions: ["AMSmath.js", "AMSsymbols.js"] ,
			TagSide: "left",
  		Macros:
  			{
  				b: ['\\overline{#1}',1],
  				h: ['\\widehat{#1}',1],
  				til: ['\\widetilde{#1}',1],
				bold: ['\\mathbf{#1}',1],  				
  				sans: ['\\mathsf{#1}',1],
					logb:	['\\overline{\\log}(#1)',1],
 				zeros: ['\\mathbf{0}'],
 				ones: ['\\mathbf{1}'],
 				complex: ['\\mathbf{C}'],
 				C: ['\\mathsf{c}'],
				d: ['\\,d'],
 				expect: ['\\mathbf{E}'],
 				emf: ['\\mathscr{E}'],
 				ft: ['\\mathcal{F}'],
 				Lagrange: ['\\mathscr{L}'],
 				naturals: ['\\mathbf{N}'],
 				normal: ['\\mathcal{N}'],
 				Z: ['\\mathbb{Z}'],
 				pset: ['\\mathcal{P}'],
 				rationals: ['\\mathbf{Q}'],
 				reals: ['\\mathbf{R}'],
 				ereals: ['\\overline{\\mathbf{R}}'],
 				risk: ['\\mathcal{R}'],
 				integers: ['\\mathbf{Z}'],
 				symdiff: ['\\,\\Delta\\,'],
 				grad: ['\\nabla'],
 				emptyset: ['\\varnothing'],
 				ortho: ['{\\bot}'],
 				deq: [':='],
 				given: ['\\mid'],
 				midgiven: ['\\;\\middle\\vert\\;'],
 				set: ['\\{\\, #1 \\,\\}', 1],
 				inner: ['\\langle#1,#2\\rangle', 2],
 				ave: ['\\langle #1 \\rangle', 1],
 				innerlr: ['\\left\\langle#1,#2\\right\\rangle', 2],
 				avelr: ['\\left\\langle#1\\right\\rangle', 1],
 				T: ['\\top'],
 				abs: ['\\lvert#1\\rvert', 1],
 				abslr:['\\left\\lvert#1\\right\\rvert', 1],
				norm: ['\\lVert#1\\rVert', 1],
				normlr: ['\\left\\lVert#1\\right\\rVert', 1],
				zeronorm: ['\\norm{#1}_0', 1],
				zeronormlr: ['\\normlr{#1}_0', 1],
				onenorm: ['\\norm{#1}_1', 1],
				onenormlr: ['\\normlr{#1}_1', 1],
				twonorm: ['\\norm{#1}_2', 1],
				twonormlr: ['\\normlr{#1}_2', 1],
				inftynorm: ['\\norm{#1}_\\infty', 1],
				inftynormlr: ['\\normlr{#1}_\\infty', 1],
				pnorm: ['\\norm{#1}_p', 1],
				pnormlr: ['\\normlr{#1}_p', 1],
				Frobnorm: ['\\norm{#1}_\\mathrm{F}', 1],
				Frobnormlr: ['\\normlr{#1}_\\mathrm{F}', 1],
				maxnorm: ['\\norm{#1}_\\mathrm{max}', 1],
				maxnormlr:  ['\\normlr{#1}_\\mathrm{max}', 1],
				tvnorm: ['\\norm{#1}_\\mathrm{TV}', 1],
				tvnormlr: ['\\normlr{#1}_\\mathrm{TV}', 1],
				ind: ['\\mathbf{I}_{\\{ #1 \\} }', 1],
				pind: ['\\mathbf{I}(#1)', 1],
				argmin: ['\\mathop{\\mathrm{arg\\,min}}'],
				argmax: ['\\mathop{\\mathrm{arg}\\,\\max}'],
				bdiag: ['\\mathop{\\mathrm{bdiag}}'],
				bd: ['\\mathop{\\mathrm{bd}}'],
				comb: ['\\mathop{\\mathrm{comb}}'],
				codom: ['\\mathop{\\mathrm{codim}}'],
				diag: ['\\mathop{\\mathrm{diag}}'],
				dom: ['\\mathop{\\mathrm{dom}}'],
				epi: ['\\mathop{\\mathrm{epi}}'],
				hard: ['\\mathop{\\mathrm{hard}}'],
				interior: ['\\mathop{\\mathrm{int}}'],
				MSE: ['\\mathop{\\mathrm{MSE}}'],
				modop: ['\\mathop{\\mathrm{mod}}'],
				minimize: ['\\mathop{\\mathrm{minimize}}'],
				maximize: ['\\mathop{\\mathrm{maximize}}'],
				midop: ['\\mathop{\\mathrm{mid}}'],
				nint: ['\\mathop{\\mathrm{nint}}'],
				pen: ['\\mathop{\\mathrm{pen}}'],
				Poisson: ['\\mathop{\\mathrm{Poisson}}'],
				rect: ['\\mathop{\\mathrm{rect}}'],
				RMSE: ['\\mathop{\\mathrm{RMSE}}'],
				range: ['\\mathop{\\mathrm{range}}'],
				relint: ['\\mathop{\\mathrm{relint}}'],
				rank: ['\\mathop{\\mathrm{rank}}'],
				st: ['\\mathop{\\mathrm{subject\\ to}}'],
				sinc: ['\\mathop{\\mathrm{sinc}}'],
				sign: ['\\mathop{\\mathrm{sign}}'],
				sgn: ['\\mathop{\\mathrm{sgn}}'],
				soft: ['\\mathop{\\mathrm{soft}}'],
				skewop: ['\\mathop{\\mathrm{skewop}}'],
				symop: ['\\mathop{\\mathrm{symop}}'],
				SNR: ['\\mathop{\\mathrm{SNR}}'],
				poly: ['\\mathop{\\mathrm{poly}}'],
				tr: ['\\mathop{\\mathrm{tr}}'],
				var: ['\\mathop{\\mathrm{var}}'],
				MinProb: ['\\begin{aligned}' +
					'&\\minimize_{#1} & & {#2}' +
					'\\end{aligned}', 2],	
				ConMinProb: ['\\begin{aligned}' +
					'&\\minimize_{#1} & & #2 \\\\' +
					'&\\st & & #3' +
					'\\end{aligned}', 3],
				MaxProb: ['\\begin{aligned}' +
					'&\\maximize_{#1} & & {#2}' +
					'\\end{aligned}', 2],	
				ConMaxProb: ['\\begin{aligned}' +
					'&\\maximize_{#1} & & #2 \\\\' +
					'&\\st & & #3' +
					'\\end{aligned}', 3],
				ArgMinProb: ['\\begin{aligned}' +
					'#1 = &\\argmin_{#2} & & {#3}' +
					'\\end{aligned}', 3],
				ArgConMinProb: ['\\begin{aligned}' +
					'#1 = &\\argmin_{#2} & & {#3} \\\\' +
					'&\\st & & #4' +
					'\\end{aligned}', 4],
				ArgMaxProb: ['\\begin{aligned}' +
					'#1 = &\\argmax_{#2} & & {#3}' +
					'\\end{aligned}', 3],
				ArgConMaxProb: ['\\begin{aligned}' +
					'#1 = &\\argmax_{#2} & & {#3} \\\\' +
					'&\\st & & #4' +
					'\\end{aligned}', 4]
	      }
		},
	"HTML-CSS": { availableFonts: ["TeX"] }
	});
MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
	MathJax.Ajax.loadComplete("http://drz.ac/javascripts/MathJaxLocal.js");
</script>


  </body>

</html>
